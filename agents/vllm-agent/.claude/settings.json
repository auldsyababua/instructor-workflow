{
  "hooks": {
    "PreToolUse": [{
      "command": "/srv/projects/instructor-workflow/agents/vllm-agent/.claude/hooks/auto-deny.py",
      "description": "Enforce Vllm Agent directory and tool restrictions"
    }]
  },
  "contextFiles": [
    "CLAUDE.md",
    "/srv/projects/instructor-workflow/.project-context.md"
  ],
  "projectInfo": {
    "name": "Vllm Agent",
    "type": "multi-agent-system",
    "description": "Deploy and manage vLLM inference server for high-performance LLM serving with OpenAI-compatible API, model management, performance optimization, and integration with agentic workflows"
  }
}
